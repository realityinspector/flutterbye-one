We've updated our Terms of Service and Privacy Policy. By continuing to use the service, you agree to these new terms.

Skip to content

OpenRouter
Search models
/
Models
Chat
Rankings
Docs

Avatar for undefined

Input Modalities
Text
Image
File

Context length
4K
64K
1M

Prompt pricing
FREE
$0.5
$10+

Series
GPT
Claude
Gemini
More…

Categories
Roleplay

Programming
Marketing
More…

Supported Parameters
tools
temperature
top_p
More…

Providers
AI21
AionLabs
Alibaba
More…
Models
10 models
Reset Filters
Filter models
SortNewest
Top Weekly
Pricing: Low to High
Pricing: High to Low
Context: High to Low
Throughput: High to Low
Latency: Low to High


Google: Gemini 2.5 Flash Preview
99.1B tokens

Health (#1)

Legal (#2)

Programming (#3)

Technology (#4)

Translation (#4)

+6 categories
Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks. It includes built-in "thinking" capabilities, enabling it to provide responses with greater accuracy and nuanced context handling.   Note: This model is available in two variants: thinking and non-thinking. The output pricing varies significantly depending on whether the thinking capability is active. If you select the standard variant (without the ":thinking" suffix), the model will explicitly avoid generating thinking tokens.   To utilize the thinking capability and receive thinking tokens, you must choose the ":thinking" variant, which will then incur the higher thinking-output pricing.   Additionally, Gemini 2.5 Flash is configurable through the "max tokens for reasoning" parameter, as described in the documentation (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning).

by google
1.05M context
$0.15/M input tokens
$0.60/M output tokens
$0.619/K input imgs
DeepSeek: DeepSeek V3 0324
56.9B tokens

Roleplay (#2)

Finance (#5)
DeepSeek V3, a 685B-parameter, mixture-of-experts model, is the latest iteration of the flagship chat model family from the DeepSeek team.  It succeeds the DeepSeek V3 model and performs really well on a variety of tasks.

by deepseek
64K context
$0.27/M input tokens
$1.10/M output tokens
Anthropic: Claude 3.7 Sonnet
254B tokens

Programming (#1)

Marketing/Seo (#1)

Technology (#2)

Marketing (#3)

Roleplay (#3)

+4 categories
Claude 3.7 Sonnet is an advanced large language model with improved reasoning, coding, and problem-solving capabilities. It introduces a hybrid reasoning approach, allowing users to choose between rapid responses and extended, step-by-step processing for complex tasks. The model demonstrates notable improvements in coding, particularly in front-end development and full-stack updates, and excels in agentic workflows, where it can autonomously navigate multi-step processes.   Claude 3.7 Sonnet maintains performance parity with its predecessor in standard mode while offering an extended reasoning mode for enhanced accuracy in math, coding, and instruction-following tasks.  Read more at the blog post here

by anthropic
200K context
$3/M input tokens
$15/M output tokens
$4.80/K input imgs
Google: Gemini 2.0 Flash
219B tokens

Legal (#1)

Trivia (#1)

Marketing (#1)

Academia (#1)

Roleplay (#1)

+7 categories
Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5, while maintaining quality on par with larger models like Gemini Pro 1.5. It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.

by google
1M context
$0.10/M input tokens
$0.40/M output tokens
$0.026/K input imgs
Mistral: Mistral Small 3
6.38B tokens

Academia (#4)

Roleplay (#6)
Mistral Small 3 is a 24B-parameter language model optimized for low-latency performance across common AI tasks. Released under the Apache 2.0 license, it features both pre-trained and instruction-tuned versions designed for efficient local deployment.  The model achieves 81% accuracy on the MMLU benchmark and performs competitively with larger models like Llama 3.3 70B and Qwen 32B, while operating at three times the speed on equivalent hardware. Read the blog post about the model here.

by mistralai
28K context
$0.06/M input tokens
$0.12/M output tokens
Nous: Hermes 3 70B Instruct
4.98B tokens

Roleplay (#4)
Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.  Hermes 3 70B is a competitive, if not superior finetune of the Llama-3.1 70B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.  The Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.

by nousresearch
131K context
$0.12/M input tokens
$0.30/M output tokens
Mistral: Mistral Nemo
24.2B tokens

Trivia (#2)

Roleplay (#8)
A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.  The model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.  It supports function calling and is released under the Apache 2.0 license.

by mistralai
98K context
$0.03/M input tokens
$0.07/M output tokens
WizardLM-2 8x22B
8.29B tokens

Roleplay (#10)
WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.  It is an instruct finetune of Mixtral 8x22B.  To read more about the model release, click here.  #moe

by microsoft
66K context
$0.50/M input tokens
$0.50/M output tokens
Anthropic: Claude 3 Haiku
3.19B tokens

Roleplay (#9)
Claude 3 Haiku is Anthropic's fastest and most compact model for near-instant responsiveness. Quick and accurate targeted performance.  See the launch announcement and benchmark results here  #multimodal

by anthropic
200K context
$0.25/M input tokens
$1.25/M output tokens
$0.40/K input imgs
MythoMax 13B
3.97B tokens

Roleplay (#5)
One of the highest performing and most popular fine-tunes of Llama 2 13B, with rich descriptions and roleplay. #merge

by gryphe
4K context
$0.065/M input tokens
$0.065/M output tokens

Status
Announcements
Partners
Careers
Pricing
Privacy
Terms
 
© 2023 – 2025 OpenRouter, Inc




Models | OpenRouter